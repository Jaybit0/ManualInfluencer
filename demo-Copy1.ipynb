{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"scenes\": [\n",
      "    {\n",
      "      \"visual\": \"Person hantiert mit einem Powerline Adapter\",\n",
      "      \"audio\": \"Bevor Sie die TechniSat PowerLine Webcast 3 Adapter in Betrieb nehmen, sollten Sie prüfen ob das Gerät in die Steckdose gesteckt ist. Sollte sich Ihr Einsatz einer Mehrfachsteckdose nicht vermeiden lassen, testen Sie die Verbindung mit nahe beieinanderliegenden Steckdosen. Schliessen Sie beide Geräte wie im Vorfeld beschrieben an, danach müssen Sie das Gerät unbedingt am Versorgungsnetz betreiben! Helfen die beschriebenen Schritte nicht, wenden Sie sich an die Hotline.\"\n",
      "    }\n",
      "  ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "from manual_influencer import constants, script_generator\n",
    "\n",
    "mjson = script_generator.generate_script(text=constants.TEXT_AND_PDF_TO_SCENES_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.loads(mjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import base64\n",
    "\n",
    "def generate(prompt):\n",
    "    client = genai.Client(\n",
    "      vertexai=True,\n",
    "      project=\"bliss-hack25fra-9587\",\n",
    "      location=\"global\",\n",
    "    )\n",
    "\n",
    "    si_text1 = \"\"\"make an english description of an image matching this scene description. black and white, rough sketch, cartoonish style. only answer with the description. no other text.\"\"\"\n",
    "\n",
    "    model = \"gemini-2.0-flash-001\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "          role=\"user\",\n",
    "          parts=[\n",
    "            types.Part.from_text(text=prompt)\n",
    "          ]\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature = 1,\n",
    "        top_p = 0.95,\n",
    "        max_output_tokens = 8192,\n",
    "        response_modalities = [\"TEXT\"],\n",
    "        safety_settings = [types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "          threshold=\"OFF\"\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "          threshold=\"OFF\"\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "          threshold=\"OFF\"\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "          threshold=\"OFF\"\n",
    "        )],\n",
    "        system_instruction=[types.Part.from_text(text=si_text1)],\n",
    "    )\n",
    "\n",
    "    mstr = ''\n",
    "\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model = model,\n",
    "        contents = contents,\n",
    "        config = generate_content_config,\n",
    "        ):\n",
    "        print(chunk.text, end=\"\")\n",
    "        mstr += chunk.text\n",
    "\n",
    "    return mstr\n",
    "    \n",
    "\n",
    "#generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import ImageGenerationModel\n",
    "import vertexai\n",
    "\n",
    "#pmt = \"A close-up, roughly sketched, black and white cartoon drawing of a powerline adapter, suggesting a simple, perhaps technical illustration.\"\n",
    "def generate_image(prompt, filename):\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    vertexai.init(project=\"bliss-hack25fra-9587\", location=\"us-central1\")\n",
    "    generation_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
    "\n",
    "    images = generation_model.generate_images(\n",
    "        prompt=prompt,\n",
    "        number_of_images=4,\n",
    "        aspect_ratio=\"9:16\",\n",
    "        negative_prompt=\"\",\n",
    "        person_generation=\"\",\n",
    "        safety_filter_level=\"\",\n",
    "        add_watermark=True,\n",
    "    )\n",
    "\n",
    "    images[0].save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import imageio_ffmpeg\n",
    "import ffmpeg\n",
    "\n",
    "def generate_video(image_folder = 'data/images', audio_file = './data/synthesis.wav', output_file = './data/out.mp4'):\n",
    "    try:\n",
    "        os.remove('./finished_video.mp4')\n",
    "        os.remove('./video.avi')\n",
    "        os.remove('./video.mp4')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter('./video.avi', 0, 0.25, (width,height))\n",
    "\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "    #cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "\n",
    "\n",
    "    ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "    subprocess.run([\n",
    "        ffmpeg_exe,\n",
    "        '-y',               # overwrite output if exists\n",
    "        '-i', 'video.avi',  # input video\n",
    "        '-c:v', 'libx264',  # video codec\n",
    "        '-c:a', 'aac',      # audio codec\n",
    "        '-shortest',        # finish when the shorter stream ends\n",
    "        'video.mp4'         # output file\n",
    "    ])\n",
    "    \n",
    "    subprocess.run([\n",
    "        ffmpeg_exe,\n",
    "        '-y',\n",
    "        '-i', 'video.mp4',\n",
    "        '-i', audio_file,\n",
    "        '-c:v', 'copy',\n",
    "        '-c:a', 'aac',\n",
    "        '-shortest',\n",
    "        output_file\n",
    "    ])\n",
    "\n",
    "    #input_video = ffmpeg.input('./video.mp4')\n",
    "\n",
    "    #input_audio = ffmpeg.input(audio_file)\n",
    "\n",
    "    #ffmpeg.concat(input_video, input_audio, v=1, a=1).output(output_file).run(cmd=ffmpeg_exe)\n",
    "    os.remove('./video.avi')\n",
    "    os.remove('./video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import wave\n",
    "import contextlib\n",
    "from mutagen.mp3 import MP3\n",
    "\n",
    "def get_audio_duration(filepath):\n",
    "    audio = MP3(filepath)\n",
    "    print(audio.info.length)\n",
    "    return audio.info.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import imageio_ffmpeg\n",
    "import os\n",
    "\n",
    "def concat_videos(video_paths, output_path='concatenated.mp4'):\n",
    "    # Create the concat input text file\n",
    "    with open('concat_list.txt', 'w') as f:\n",
    "        for path in video_paths:\n",
    "            f.write(f\"file '{os.path.abspath(path)}'\\n\")\n",
    "\n",
    "    ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "    # Run ffmpeg concat\n",
    "    subprocess.run([\n",
    "        ffmpeg_exe,\n",
    "        '-f', 'concat',\n",
    "        '-safe', '0',\n",
    "        '-i', 'concat_list.txt',\n",
    "        '-c', 'copy',\n",
    "        output_path\n",
    "    ])\n",
    "\n",
    "    os.remove('concat_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'visual': 'Person hantiert mit einem Powerline Adapter', 'audio': 'Bevor Sie die TechniSat PowerLine Webcast 3 Adapter in Betrieb nehmen, sollten Sie prüfen ob das Gerät in die Steckdose gesteckt ist. Sollte sich Ihr Einsatz einer Mehrfachsteckdose nicht vermeiden lassen, testen Sie die Verbindung mit nahe beieinanderliegenden Steckdosen. Schliessen Sie beide Geräte wie im Vorfeld beschrieben an, danach müssen Sie das Gerät unbedingt am Versorgungsnetz betreiben! Helfen die beschriebenen Schritte nicht, wenden Sie sich an die Hotline.'}\n",
      "A simple, cartoonish sketch of a person fiddling with a powerline adapter.\n",
      "Audio content written to file \"./data/audio/output.mp3\"\n",
      "28.392\n",
      "Prompt: A roughly sketched, cartoonish black and white image; A simple, cartoonish sketch of a person fiddling with a powerline adapter.\n",
      "\n",
      "Prompt: A roughly sketched, cartoonish black and white image; A simple, cartoonish sketch of a person fiddling with a powerline adapter.\n",
      "\n",
      "Prompt: A roughly sketched, cartoonish black and white image; A simple, cartoonish sketch of a person fiddling with a powerline adapter.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from manual_influencer.tts import synthesize_speech\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "folder = './data/visual'\n",
    "for f in os.listdir(folder):\n",
    "    path = os.path.join(folder, f)\n",
    "    if os.path.isfile(path):\n",
    "        os.remove(path)\n",
    "        \n",
    "try:\n",
    "    os.remove('./concatenated.mp4')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for mp4_file in Path('.').glob('*.mp4'):\n",
    "    try:\n",
    "        os.remove(mp4_file)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "images = []\n",
    "idx = 0\n",
    "\n",
    "for scene in data['scenes']:\n",
    "    print(scene)\n",
    "    visual = \"A roughly sketched, cartoonish black and white image with no text; \"\n",
    "    visual += generate(scene['visual'])\n",
    "    synthesize_speech(text=scene['audio'], output_file='./data/audio/output.mp3')\n",
    "    time = get_audio_duration('./data/audio/output.mp3')\n",
    "    for i in range(1, int(time/4+1)):\n",
    "        generate_image(visual, './data/visual/images_00' + str(i) + '.png')\n",
    "    generate_video(image_folder='./data/visual', audio_file='./data/audio/output.mp3', output_file = str(idx) + '.mp4')\n",
    "    for f in os.listdir(folder):\n",
    "        path = os.path.join(folder, f)\n",
    "        if os.path.isfile(path):\n",
    "            os.remove(path)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ml = []\n",
    "\n",
    "for mp4_file in Path('.').glob('*.mp4'):\n",
    "    ml.append(mp4_file)\n",
    "    \n",
    "concat_videos(ml)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
