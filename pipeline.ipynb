{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:22:03.579536500Z",
     "start_time": "2025-04-01T22:22:03.568536200Z"
    }
   },
   "outputs": [],
   "source": [
    "from manual_influencer import constants, script_generator\n",
    "\n",
    "#mjson = script_generator.generate_script(text=constants.TEXT_TO_SCENES_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-01T22:22:03.599536Z",
     "start_time": "2025-04-01T22:22:03.580536600Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "#data = json.loads(mjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-01T22:22:03.614537700Z",
     "start_time": "2025-04-01T22:22:03.601536400Z"
    }
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import base64\n",
    "\n",
    "def generate_scene_image_description(prompt):\n",
    "    client = genai.Client(\n",
    "      vertexai=True,\n",
    "      project=constants.GCP_PROJECT_ID,\n",
    "      location=\"global\",\n",
    "    )\n",
    "\n",
    "    si_text1 = \"\"\"make an english description of an image matching this scene description. black and white, rough sketch, cartoonish style. describe the objects rather than using technical terms. only answer with the description. no other text.\"\"\"\n",
    "\n",
    "    model = \"gemini-2.0-flash-001\"\n",
    "    contents = [\n",
    "        types.Content(\n",
    "          role=\"user\",\n",
    "          parts=[\n",
    "            types.Part.from_text(text=prompt)\n",
    "          ]\n",
    "        ),\n",
    "    ]\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature = 1,\n",
    "        top_p = 0.95,\n",
    "        max_output_tokens = 8192,\n",
    "        response_modalities = [\"TEXT\"],\n",
    "        safety_settings = [types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "          threshold=\"OFF\"\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "          threshold=\"OFF\"\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "          threshold=\"OFF\"\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "          threshold=\"OFF\"\n",
    "        )],\n",
    "        system_instruction=[types.Part.from_text(text=si_text1)],\n",
    "    )\n",
    "\n",
    "    mstr = ''\n",
    "\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model = model,\n",
    "        contents = contents,\n",
    "        config = generate_content_config,\n",
    "        ):\n",
    "        print(chunk.text, end=\"\")\n",
    "        mstr += chunk.text\n",
    "\n",
    "    return mstr\n",
    "    \n",
    "\n",
    "#generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-01T22:22:03.641539600Z",
     "start_time": "2025-04-01T22:22:03.614537700Z"
    }
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import ImageGenerationModel\n",
    "import vertexai\n",
    "\n",
    "#pmt = \"A close-up, roughly sketched, black and white cartoon drawing of a powerline adapter, suggesting a simple, perhaps technical illustration.\"\n",
    "def generate_image(prompt, filename):\n",
    "    print(\"Prompt: \" + prompt)\n",
    "    vertexai.init(project=constants.GCP_PROJECT_ID, location=\"us-central1\")\n",
    "    generation_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
    "\n",
    "    images = generation_model.generate_images(\n",
    "        prompt=prompt,\n",
    "        number_of_images=1,\n",
    "        aspect_ratio=\"9:16\",\n",
    "        negative_prompt=\"\",\n",
    "        person_generation=\"\",\n",
    "        safety_filter_level=\"\",\n",
    "        add_watermark=True,\n",
    "    )\n",
    "\n",
    "    images[0].save(filename)\n",
    "    \n",
    "# generate_image(\"A close-up, roughly sketched, black and white cartoon drawing of a powerline adapter, suggesting a simple, perhaps technical illustration\", \"data/visual/example.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import wave\n",
    "import contextlib\n",
    "from mutagen.mp3 import MP3\n",
    "\n",
    "def get_audio_duration(filepath):\n",
    "    audio = MP3(filepath)\n",
    "    print(audio.info.length)\n",
    "    return audio.info.length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T22:22:03.643537800Z",
     "start_time": "2025-04-01T22:22:03.627539800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-01T22:22:03.673538100Z",
     "start_time": "2025-04-01T22:22:03.642536700Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "import imageio_ffmpeg\n",
    "import ffmpeg\n",
    "import math\n",
    "import gc\n",
    "import time\n",
    "\n",
    "def generate_video(image_folder = 'data/images', audio_file = './data/synthesis.wav', output_file = './data/out.mp4'):\n",
    "    try:\n",
    "        os.remove('./finished_video.mp4')\n",
    "        os.remove('./video.avi')\n",
    "        os.remove('./video.mp4')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter('./video.avi', 0, 30, (width,height))\n",
    "    \n",
    "    audio_duration = get_audio_duration(audio_file)\n",
    "    vid_duration_frames = audio_duration * 30\n",
    "    frame_count_per_image = int(math.ceil(vid_duration_frames / len(images)))\n",
    "\n",
    "    for image in images:\n",
    "        for _ in range(frame_count_per_image):\n",
    "            video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "    #cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "    \n",
    "    ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "    subprocess.run([\n",
    "        ffmpeg_exe,\n",
    "        '-y',               # overwrite output if exists\n",
    "        '-i', 'video.avi',  # input video\n",
    "        '-c:v', 'libx264',  # video codec\n",
    "        '-c:a', 'aac',      # audio codec\n",
    "        '-shortest',        # finish when the shorter stream ends\n",
    "        'video.mp4'         # output file\n",
    "    ])\n",
    "    \n",
    "    subprocess.run([\n",
    "        ffmpeg_exe,\n",
    "        '-y',\n",
    "        '-i', 'video.mp4',\n",
    "        '-i', audio_file,\n",
    "        '-c:v', 'copy',\n",
    "        '-c:a', 'aac',\n",
    "        '-shortest',\n",
    "        output_file\n",
    "    ])\n",
    "\n",
    "    #input_video = ffmpeg.input('./video.mp4')\n",
    "\n",
    "    #input_audio = ffmpeg.input(audio_file)\n",
    "\n",
    "    gc.collect()\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    #ffmpeg.concat(input_video, input_audio, v=1, a=1).output(output_file).run(cmd=ffmpeg_exe)\n",
    "    os.remove('./video.avi')\n",
    "    os.remove('./video.mp4')\n",
    "\n",
    "# generate_video(image_folder=\"./data/visual\", audio_file='./data/audio/output.mp3', output_file = '0.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-01T22:22:03.694536600Z",
     "start_time": "2025-04-01T22:22:03.677537800Z"
    }
   },
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import imageio_ffmpeg\n",
    "import os\n",
    "\n",
    "def concat_videos(video_paths, output_path='concatenated.mp4'):\n",
    "    # Create the concat input text file\n",
    "    with open('concat_list.txt', 'w') as f:\n",
    "        for path in video_paths:\n",
    "            f.write(f\"file '{os.path.abspath(path)}'\\n\")\n",
    "\n",
    "    ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "    # Run ffmpeg concat\n",
    "    subprocess.run([\n",
    "        ffmpeg_exe,\n",
    "        '-f', 'concat',\n",
    "        '-safe', '0',\n",
    "        '-i', 'concat_list.txt',\n",
    "        '-c', 'copy',\n",
    "        output_path\n",
    "    ])\n",
    "\n",
    "    os.remove('concat_list.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.effects import speedup\n",
    "\n",
    "def speedup_speech(input_file='./data/audio/output_raw.mp3', output_file='./data/audio/output.mp3', speed=1.4):\n",
    "    audio = AudioSegment.from_file(input_file)\n",
    "    faster_audio = speedup(audio, playback_speed=speed)\n",
    "    faster_audio.export(output_file, format=\"mp3\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T22:22:03.715536300Z",
     "start_time": "2025-04-01T22:22:03.690536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-01T22:25:06.356144300Z",
     "start_time": "2025-04-01T22:22:03.718536100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"scenes\": [\n",
      "    {\n",
      "      \"visual\": \"Ein Mann versucht mit einem überdimensionalen Gummihammer ein rohes Ei zu zerbrechen.\",\n",
      "      \"audio\": \"Ich hab's gleich...Moment...Nur noch ein kleiner Schubs.\"\n",
      "    },\n",
      "    {\n",
      "      \"visual\": \"Das Ei ist unversehrt. Der Mann holt einen Winkelschleifer aus dem Werkzeugkoffer.\",\n",
      "      \"audio\": \"Das Ei ist wohl doch härter als gedacht. Dann muss wohl die Schleifkraft ran.\"\n",
      "    },\n",
      "    {\n",
      "      \"visual\": \"Nahaufnahme des Winkelschleifers, der mit voller Wucht auf das Ei trifft. Eigelb spritzt.\",\n",
      "      \"audio\": \"Oha! Das ging schneller als gedacht. Vielleicht doch etwas übertrieben.\"\n",
      "    },\n",
      "    {\n",
      "      \"visual\": \"Der Mann steht bedröppelt da, Eigelb bedeckt sein Gesicht und den Arbeitsbereich.\",\n",
      "      \"audio\": \"Naja, wenigstens ist das Ei jetzt auf. Nächstes Mal probier ich es vielleicht doch lieber mit einem Messer.\"\n",
      "    }\n",
      "  ]\n",
      "}{'visual': 'Ein Mann versucht mit einem überdimensionalen Gummihammer ein rohes Ei zu zerbrechen.', 'audio': \"Ich hab's gleich...Moment...Nur noch ein kleiner Schubs.\"}\n",
      "A man is attempting to crack a raw egg with an oversized rubber mallet.\n",
      "Audio content written to file \"./data/audio/output_raw.mp3\"\n",
      "3.432\n",
      "Prompt: A roughly sketched, cartoonish black and white image with no text; A man is attempting to crack a raw egg with an oversized rubber mallet.\n",
      "3.432\n",
      "{'visual': 'Das Ei ist unversehrt. Der Mann holt einen Winkelschleifer aus dem Werkzeugkoffer.', 'audio': 'Das Ei ist wohl doch härter als gedacht. Dann muss wohl die Schleifkraft ran.'}\n",
      "A black and white, rough sketch depicts a man holding a box, with a tool resting on top. Beside him is an egg, appearing whole.\n",
      "Audio content written to file \"./data/audio/output_raw.mp3\"\n",
      "4.08\n",
      "Prompt: A roughly sketched, cartoonish black and white image with no text; A black and white, rough sketch depicts a man holding a box, with a tool resting on top. Beside him is an egg, appearing whole.\n",
      "Prompt: A roughly sketched, cartoonish black and white image with no text; A black and white, rough sketch depicts a man holding a box, with a tool resting on top. Beside him is an egg, appearing whole.\n",
      "4.08\n",
      "{'visual': 'Nahaufnahme des Winkelschleifers, der mit voller Wucht auf das Ei trifft. Eigelb spritzt.', 'audio': 'Oha! Das ging schneller als gedacht. Vielleicht doch etwas übertrieben.'}\n",
      "Close-up of a grinder with a disc meeting an egg with full force. Yolk is spraying.\n",
      "Audio content written to file \"./data/audio/output_raw.mp3\"\n",
      "3.936\n",
      "Prompt: A roughly sketched, cartoonish black and white image with no text; Close-up of a grinder with a disc meeting an egg with full force. Yolk is spraying.\n",
      "3.936\n",
      "{'visual': 'Der Mann steht bedröppelt da, Eigelb bedeckt sein Gesicht und den Arbeitsbereich.', 'audio': 'Naja, wenigstens ist das Ei jetzt auf. Nächstes Mal probier ich es vielleicht doch lieber mit einem Messer.'}\n",
      "A man stands dejectedly, yolk covers his face and the surrounding workspace.\n",
      "Audio content written to file \"./data/audio/output_raw.mp3\"\n",
      "5.592\n",
      "Prompt: A roughly sketched, cartoonish black and white image with no text; A man stands dejectedly, yolk covers his face and the surrounding workspace.\n",
      "Prompt: A roughly sketched, cartoonish black and white image with no text; A man stands dejectedly, yolk covers his face and the surrounding workspace.\n",
      "5.592\n",
      "Creating vid: 1\n"
     ]
    }
   ],
   "source": [
    "from manual_influencer.tts import synthesize_speech\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "\n",
    "seconds_per_image = 4\n",
    "\n",
    "for mp4_file in Path('./vids/').glob('*.mp4'):\n",
    "    try:\n",
    "        os.remove(mp4_file)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for k in range(1, 2):\n",
    "    try:\n",
    "        os.makedirs(\"vids\", exist_ok=True)\n",
    "        os.makedirs(\"data\", exist_ok=True)\n",
    "        os.makedirs(\"data/visual\", exist_ok=True)\n",
    "        os.makedirs(\"data/audio\", exist_ok=True)\n",
    "        \n",
    "        mjson = script_generator.generate_script(text=constants.TEXT_TO_SCENES_PROMPT)\n",
    "        data = json.loads(mjson)\n",
    "        \n",
    "        visual_folder = './data/visual'\n",
    "        for f in os.listdir(visual_folder):\n",
    "            path = os.path.join(visual_folder, f)\n",
    "            if os.path.isfile(path):\n",
    "                os.remove(path)\n",
    "\n",
    "        try:\n",
    "            os.remove('./concatenated.mp4')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for mp4_file in Path('.').glob('*.mp4'):\n",
    "            try:\n",
    "                os.remove(mp4_file)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        images = []\n",
    "        idx = 0\n",
    "\n",
    "        for scene in data['scenes']:\n",
    "            print(scene)\n",
    "            visual = \"A roughly sketched, cartoonish black and white image with no text; \"\n",
    "            visual += generate_scene_image_description(scene['visual'])\n",
    "            synthesize_speech(text=scene['audio'], output_file='./data/audio/output_raw.mp3')\n",
    "            speedup_speech(input_file='./data/audio/output_raw.mp3', output_file='./data/audio/output.mp3', speed=1.2)\n",
    "            time_in_s = get_audio_duration('./data/audio/output.mp3')\n",
    "            for i in range(1, int(time_in_s / 4 + 2)):\n",
    "                generate_image(visual, visual_folder + '/images_00' + str(i) + '.png')\n",
    "                time.sleep(16)\n",
    "            generate_video(image_folder=visual_folder, audio_file='./data/audio/output.mp3', output_file = str(idx) + '.mp4')\n",
    "            for f in os.listdir(visual_folder):\n",
    "                path = os.path.join(visual_folder, f)\n",
    "                if os.path.isfile(path):\n",
    "                    os.remove(path)\n",
    "            idx += 1\n",
    "\n",
    "        ml = []\n",
    "\n",
    "        for mp4_file in Path('.').glob('*.mp4'):\n",
    "            ml.append(mp4_file)\n",
    "\n",
    "        print('Creating vid: ' + str(k))\n",
    "        concat_videos(ml, output_path='./vids/vid_' + str(k) + '.mp4')\n",
    "    except Exception as e:\n",
    "        print(\"error:\", e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-01T22:25:06.378143700Z",
     "start_time": "2025-04-01T22:25:06.358149400Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ml = []\n",
    "\n",
    "#for mp4_file in Path('.').glob('*.mp4'):\n",
    "#    ml.append(mp4_file)\n",
    "    \n",
    "#concat_videos(ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-01T22:25:06.390146300Z",
     "start_time": "2025-04-01T22:25:06.374146900Z"
    }
   }
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
